{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was both designed and written by me. I primarily used ChatGPT and Copilot for debugging, identifying errors, and improving efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathi\\AppData\\Local\\Temp\\ipykernel_9416\\3693878389.py:9: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_2009_2019 = pd.read_csv(csv_file, encoding=\"utf-8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne dataset 1919-2013: Index(['speechID', 'memberID', 'partyID', 'constID', 'title', 'date',\n",
      "       'member_name', 'party_name', 'const_name', 'speech'],\n",
      "      dtype='object')\n",
      "Colonne dataset 2009-2019: Index(['instance_id', 'date', 'agenda', 'speechnumber', 'paragraphnumber',\n",
      "       'sentencenumber', 'speaker', 'party', 'text', 'parliament',\n",
      "       'iso3country', 'speaker_uri', 'eu', 'policyarea', 'cmp_party'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "tab_file = r\"C:/Users/mathi/OneDrive - University College Dublin/UCDlectures/AILLMS/groupwork/coding_part/dataverse_files/Dail_debates_1919-2013/Dail_debates_1919-2013.tab\"\n",
    "csv_file = r\"C:/Users/mathi/OneDrive - University College Dublin/UCDlectures/AILLMS/groupwork/coding_part/dataverse_files/dail-speeches_2009-2019.csv\"\n",
    "\n",
    "df_1919_2013 = pd.read_csv(tab_file, sep=\"\\t\", encoding=\"utf-8\")\n",
    "df_2009_2019 = pd.read_csv(csv_file, encoding=\"utf-8\")\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "df_1919_2013[\"date\"] = pd.to_datetime(df_1919_2013[\"date\"], format=\"%Y-%m-%d\")\n",
    "df_2009_2019[\"date\"] = pd.to_datetime(df_2009_2019[\"date\"], format=\"%d/%m/%Y\", dayfirst=True)\n",
    "\n",
    "# Check the main columns\n",
    "print(\"Columns in dataset 1919-2013:\", df_1919_2013.columns)\n",
    "print(\"Columns in dataset 2009-2019:\", df_2009_2019.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1919_2013_filtered = df_1919_2013[df_1919_2013[\"date\"] < pd.Timestamp(2009, 1, 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicati in speechID (1919-2013): 0\n",
      "Duplicati in instance_id (2009-2019): 0\n"
     ]
    }
   ],
   "source": [
    "# Check uniqueness of IDs in the historical dataset\n",
    "print(\"Duplicates in speechID (1919-2013):\", df_1919_2013[\"speechID\"].duplicated().sum())\n",
    "\n",
    "# Check uniqueness of IDs in the recent dataset\n",
    "print(\"Duplicates in instance_id (2009-2019):\", df_2009_2019[\"instance_id\"].duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009_2019.rename(columns={\n",
    "    \"instance_id\": \"speechID\",       \n",
    "    \"agenda\": \"title\",              \n",
    "    \"speaker\": \"member_name\",       \n",
    "    \"party\": \"party_name\",          \n",
    "    \"text\": \"speech\"                \n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathi\\AppData\\Local\\Temp\\ipykernel_9416\\163158017.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1919_2013_filtered[\"speechID\"] = \"HIST_\" + df_1919_2013_filtered[\"speechID\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Add prefix to the historical dataset\n",
    "df_1919_2013_filtered[\"speechID\"] = \"HIST_\" + df_1919_2013_filtered[\"speechID\"].astype(str)\n",
    "\n",
    "# Add prefix to the recent dataset\n",
    "df_2009_2019[\"speechID\"] = \"REC_\" + df_2009_2019[\"speechID\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_1919_2013_filtered, df_2009_2019], ignore_index=True)\n",
    "df_final.sort_values(by=\"date\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informazioni sul dataset finale:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7923506 entries, 0 to 7545002\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   speechID         object        \n",
      " 1   memberID         float64       \n",
      " 2   partyID          float64       \n",
      " 3   constID          float64       \n",
      " 4   title            object        \n",
      " 5   date             datetime64[ns]\n",
      " 6   member_name      object        \n",
      " 7   party_name       object        \n",
      " 8   const_name       object        \n",
      " 9   speech           object        \n",
      " 10  speechnumber     float64       \n",
      " 11  paragraphnumber  float64       \n",
      " 12  sentencenumber   float64       \n",
      " 13  parliament       object        \n",
      " 14  iso3country      object        \n",
      " 15  speaker_uri      object        \n",
      " 16  eu               float64       \n",
      " 17  policyarea       float64       \n",
      " 18  cmp_party        object        \n",
      "dtypes: datetime64[ns](1), float64(8), object(10)\n",
      "memory usage: 1.2+ GB\n",
      "None\n",
      "Numero di duplicati nel dataset finale: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Information about the final dataset:\")\n",
    "print(df_final.info())\n",
    "\n",
    "# Check for duplicates based on the unique ID created\n",
    "duplicates = df_final.duplicated(subset=[\"speechID\", \"date\"]).sum()\n",
    "print(f\"Number of duplicates in the final dataset: {duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informazioni sul dataset finale:\n",
      "Index(['speechID', 'memberID', 'partyID', 'constID', 'title', 'date',\n",
      "       'member_name', 'party_name', 'const_name', 'speech', 'speechnumber',\n",
      "       'paragraphnumber', 'sentencenumber', 'parliament', 'iso3country',\n",
      "       'speaker_uri', 'eu', 'policyarea', 'cmp_party', 'year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Creazione della colonna 'year' dal campo 'date'\n",
    "df_final[\"year\"] = df_final[\"date\"].dt.year\n",
    "\n",
    "print(\"Informazioni sul dataset finale:\")\n",
    "print(df_final.columns)\n",
    "\n",
    "# Filtraggio dei dati per anno >= 1950\n",
    "df_final_filtered = df_final[df_final[\"year\"] >= 1950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-19.0.1-cp310-cp310-win_amd64.whl (25.3 MB)\n",
      "     ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/25.3 MB 1.3 MB/s eta 0:00:20\n",
      "     ---------------------------------------- 0.2/25.3 MB 2.4 MB/s eta 0:00:11\n",
      "      --------------------------------------- 0.5/25.3 MB 3.2 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.9/25.3 MB 4.6 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 1.3/25.3 MB 5.4 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 1.7/25.3 MB 5.9 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 2.1/25.3 MB 6.3 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 2.4/25.3 MB 6.4 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 2.8/25.3 MB 6.5 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 3.2/25.3 MB 6.7 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 3.5/25.3 MB 6.8 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 3.9/25.3 MB 6.9 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 4.1/25.3 MB 6.7 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 4.5/25.3 MB 6.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 4.9/25.3 MB 7.0 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 5.2/25.3 MB 7.1 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 5.6/25.3 MB 7.2 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 6.0/25.3 MB 7.2 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 6.4/25.3 MB 7.3 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 6.8/25.3 MB 7.4 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 7.2/25.3 MB 7.4 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 7.5/25.3 MB 7.4 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 7.8/25.3 MB 7.4 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 8.1/25.3 MB 7.3 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 8.7/25.3 MB 7.5 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 9.0/25.3 MB 7.5 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 9.4/25.3 MB 7.5 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 9.8/25.3 MB 7.5 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 9.9/25.3 MB 7.4 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 10.3/25.3 MB 7.5 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 10.7/25.3 MB 7.8 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 11.0/25.3 MB 7.8 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 11.3/25.3 MB 7.8 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 11.7/25.3 MB 7.7 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 12.1/25.3 MB 7.8 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 12.5/25.3 MB 8.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 12.9/25.3 MB 7.9 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 13.4/25.3 MB 8.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 13.7/25.3 MB 7.9 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 14.1/25.3 MB 7.9 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 14.5/25.3 MB 8.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 14.9/25.3 MB 8.1 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 15.2/25.3 MB 8.1 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 15.7/25.3 MB 8.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 16.0/25.3 MB 8.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 16.5/25.3 MB 8.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 16.9/25.3 MB 8.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 17.3/25.3 MB 8.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 17.7/25.3 MB 8.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 18.0/25.3 MB 8.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 18.3/25.3 MB 8.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 18.6/25.3 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 19.0/25.3 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 19.3/25.3 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 19.7/25.3 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 20.1/25.3 MB 8.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 20.5/25.3 MB 8.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 20.7/25.3 MB 8.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 21.1/25.3 MB 8.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 21.6/25.3 MB 8.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 21.9/25.3 MB 8.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 22.1/25.3 MB 8.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 22.4/25.3 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 22.8/25.3 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 23.1/25.3 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 23.5/25.3 MB 7.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 23.9/25.3 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 24.2/25.3 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 24.5/25.3 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.8/25.3 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  25.1/25.3 MB 7.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  25.3/25.3 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  25.3/25.3 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  25.3/25.3 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 25.3/25.3 MB 6.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-19.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyarrow\n",
    "%pip install pyarrow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   nan 53620. 53320. 53520. 53951. 53420. 53110. 53230. 53231. 53250.\n",
      " 53321. 53240.]\n",
      "float64\n",
      "        cmp_party\n",
      "703741        NaN\n",
      "703751        NaN\n",
      "703752        NaN\n",
      "703749        NaN\n",
      "703748        NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathi\\AppData\\Local\\Temp\\ipykernel_9416\\1899037589.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_filtered[\"cmp_party\"] = df_final_filtered[\"cmp_party\"].replace(\"-\", np.nan)\n",
      "C:\\Users\\mathi\\AppData\\Local\\Temp\\ipykernel_9416\\1899037589.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_filtered[\"cmp_party\"] = pd.to_numeric(df_final_filtered[\"cmp_party\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "# Mostra i valori unici nella colonna cmp_party\n",
    "print(df_final_filtered[\"cmp_party\"].unique())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sostituisci il simbolo '-' con NaN\n",
    "df_final_filtered[\"cmp_party\"] = df_final_filtered[\"cmp_party\"].replace(\"-\", np.nan)\n",
    "\n",
    "# Converti la colonna cmp_party in tipo numerico\n",
    "df_final_filtered[\"cmp_party\"] = pd.to_numeric(df_final_filtered[\"cmp_party\"], errors=\"coerce\")\n",
    "\n",
    "# Verifica il tipo di dato della colonna cmp_party\n",
    "print(df_final_filtered[\"cmp_party\"].dtype)\n",
    "\n",
    "# Mostra alcune righe della colonna per confermare il risultato\n",
    "print(df_final_filtered[[\"cmp_party\"]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvato in formato Parquet in: C:\\Users\\mathi\\OneDrive - University College Dublin\\UCDlectures\\AILLMS\\groupwork\\merged_dataset_filtered.parquet\n"
     ]
    }
   ],
   "source": [
    "output_file_parquet = r\"C:\\Users\\mathi\\OneDrive - University College Dublin\\UCDlectures\\AILLMS\\groupwork\\merged_dataset_filtered.parquet\"\n",
    "df_final_filtered.to_parquet(output_file_parquet, index=False)\n",
    "\n",
    "print(f\"Dataset salvato in formato Parquet in: {output_file_parquet}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
